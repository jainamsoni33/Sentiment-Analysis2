{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jainam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\jainam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "C:\\Users\\jainam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After all that, they complained to me about th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avoid this place!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Saul is the best restaurant on Smith Street an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The duck confit is always amazing and the foie...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The duck confit is always amazing and the foie...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The wine list is interesting and has many good...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The wine list is interesting and has many good...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For the price, you cannot eat this well in Man...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>For the price, you cannot eat this well in Man...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I was very disappointed with this restaurant.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ive asked a cart attendant for a lotus leaf wr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I had to ask her three times before she finall...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Food was okay, nothing great.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chow fun was dry; pork shu mai was more than u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chow fun was dry; pork shu mai was more than u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chow fun was dry; pork shu mai was more than u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I/we will never go back to this place again.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Went on a 3 day oyster binge, with Fish bringi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Service was devine, oysters where a sensual as...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Service was devine, oysters where a sensual as...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Service was devine, oysters where a sensual as...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You can't go wrong here.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Every time in New York I make it a point to vi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Everything is always cooked to perfection, the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Everything is always cooked to perfection, the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Everything is always cooked to perfection, the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I had the duck breast special on my last visit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Can't wait wait for my next visit.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I had my eyes on this place, promising myself ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>And I hate to say this but I doubt I'll ever g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The food is very average...the Thai fusion stu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The food is very average...the Thai fusion stu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The food is very average...the Thai fusion stu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The only thing I moderately enjoyed was their ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I had never had Edamame pureed before but I th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I had never had Edamame pureed before but I th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Anyways, if you're in the neighborhood to eat ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The decor is night tho...but they REALLY need ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The decor is night tho...but they REALLY need ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The decor is night tho...but they REALLY need ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>We ate outside at Haru's Sake bar because Haru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>What's the difference between the two?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Their sake list was extensive, but we were loo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Their sake list was extensive, but we were loo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence sentiment\n",
       "0   Judging from previous posts this used to be a ...  negative\n",
       "1   We, there were four of us, arrived at noon - t...  negative\n",
       "2   They never brought us complimentary noodles, i...  negative\n",
       "3   The food was lousy - too sweet or too salty an...  negative\n",
       "4   The food was lousy - too sweet or too salty an...  negative\n",
       "5   After all that, they complained to me about th...  negative\n",
       "6                                   Avoid this place!  negative\n",
       "7   I have eaten at Saul, many times, the food is ...  positive\n",
       "8   Saul is the best restaurant on Smith Street an...  positive\n",
       "9   The duck confit is always amazing and the foie...  positive\n",
       "10  The duck confit is always amazing and the foie...  positive\n",
       "11  The wine list is interesting and has many good...  positive\n",
       "12  The wine list is interesting and has many good...  positive\n",
       "13  For the price, you cannot eat this well in Man...  positive\n",
       "14  For the price, you cannot eat this well in Man...  positive\n",
       "15      I was very disappointed with this restaurant.  negative\n",
       "16  Ive asked a cart attendant for a lotus leaf wr...  negative\n",
       "17  I had to ask her three times before she finall...  negative\n",
       "18                      Food was okay, nothing great.   neutral\n",
       "19  Chow fun was dry; pork shu mai was more than u...  negative\n",
       "20  Chow fun was dry; pork shu mai was more than u...  negative\n",
       "21  Chow fun was dry; pork shu mai was more than u...  negative\n",
       "22       I/we will never go back to this place again.  negative\n",
       "23  Went on a 3 day oyster binge, with Fish bringi...  positive\n",
       "24  Service was devine, oysters where a sensual as...  positive\n",
       "25  Service was devine, oysters where a sensual as...  positive\n",
       "26  Service was devine, oysters where a sensual as...  positive\n",
       "27                           You can't go wrong here.  positive\n",
       "28  Every time in New York I make it a point to vi...  positive\n",
       "29  Everything is always cooked to perfection, the...  positive\n",
       "30  Everything is always cooked to perfection, the...  positive\n",
       "31  Everything is always cooked to perfection, the...  positive\n",
       "32  I had the duck breast special on my last visit...  positive\n",
       "33                 Can't wait wait for my next visit.  positive\n",
       "34  I had my eyes on this place, promising myself ...       NaN\n",
       "35  And I hate to say this but I doubt I'll ever g...  negative\n",
       "36  The food is very average...the Thai fusion stu...  negative\n",
       "37  The food is very average...the Thai fusion stu...  negative\n",
       "38  The food is very average...the Thai fusion stu...  negative\n",
       "39  The only thing I moderately enjoyed was their ...  positive\n",
       "40  I had never had Edamame pureed before but I th...  positive\n",
       "41  I had never had Edamame pureed before but I th...  positive\n",
       "42  Anyways, if you're in the neighborhood to eat ...       NaN\n",
       "43  The decor is night tho...but they REALLY need ...  negative\n",
       "44  The decor is night tho...but they REALLY need ...  positive\n",
       "45  The decor is night tho...but they REALLY need ...  negative\n",
       "46  We ate outside at Haru's Sake bar because Haru...       NaN\n",
       "47             What's the difference between the two?       NaN\n",
       "48  Their sake list was extensive, but we were loo...  positive\n",
       "49  Their sake list was extensive, but we were loo...  positive"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#We are going to use XML file to read the reviews of a restaurant.\n",
    "xml_path = './NLP/ABSA15_RestaurantsTrain/ABSA-15_Restaurants_Train_Final.xml'\n",
    "\n",
    "def parse_data(xml_path):\n",
    "    container = []                                              \n",
    "    reviews = ET.parse(xml_path).getroot()                      \n",
    "    \n",
    "    #getting the root of the XML file. Every review has 4-5 sentences which are it's childrens. We will seperate all the\n",
    "    #sentences to form 1849 different reviews. Two columns : sentence and it's sentiment (polarity).\n",
    "    \n",
    "    for review in reviews:  \n",
    "        sentences = review.getchildren()[0].getchildren()       \n",
    "        for sentence in sentences:                                  \n",
    "            sentence_text = sentence.getchildren()[0].text          \n",
    "            \n",
    "            try:                                                     \n",
    "                opinions = sentence.getchildren()[1].getchildren()\n",
    "            \n",
    "                for opinion in opinions:    \n",
    "                    #we are interested only in the sentence and it's polarity.\n",
    "                    #category,target,sentence id and rest everything is not important\n",
    "                    polarity = opinion.attrib[\"polarity\"]\n",
    "        \n",
    "                    row = {\"sentence\": sentence_text, \"sentiment\":polarity}   \n",
    "                    container.append(row)                                                              \n",
    "                \n",
    "            except IndexError: \n",
    "                row = {\"sentence\": sentence_text}        \n",
    "                container.append(row) \n",
    "                \n",
    "    #convert the container (corpus having all reviews) into a dataframe and return.  \n",
    "    return pd.DataFrame(container)\n",
    "\n",
    "#call the function parse_data.Storing everything in df(dataframe)\n",
    "df = parse_data(xml_path)\n",
    "\n",
    "#printing the head of the dataframe i.e first 50 reviews\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence       0\n",
       "sentiment    195\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the 195 dataframes where no sentiment is expressed\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (1849, 2)\n",
      "Drop Dupicates: (1396, 2)\n",
      "Drop Nulls: (1201, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"Original:\", df.shape)\n",
    "\n",
    "#remove duplicate reviews\n",
    "dd = df.drop_duplicates()\n",
    "dd = dd.reset_index(drop=True)\n",
    "print (\"Drop Dupicates:\", dd.shape)\n",
    "\n",
    "#removing the 195 dataframes where no sentiment is expressed\n",
    "dd_dn = dd.dropna()\n",
    "df = dd_dn.reset_index(drop=True)\n",
    "print (\"Drop Nulls:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Went on a 3 day oyster binge, with Fish bringing up the closing, and I am so glad this was the place it O trip ended, because it was so great!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#17th review for example\n",
    "df.sentence[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Went', 'on', 'a', '3', 'day', 'oyster', 'binge', ',', 'with', 'Fish', 'bringing', 'up', 'the', 'closing', ',', 'and', 'I', 'am', 'so', 'glad', 'this', 'was', 'the', 'place', 'it', 'O', 'trip', 'ended', ',', 'because', 'it', 'was', 'so', 'great', '!']\n"
     ]
    }
   ],
   "source": [
    "#natural language toolkit (nltk)\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "#using tokenize library for tokenization. Pre-processing starts\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(df.sentence[17])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Went', '3', 'day', 'oyster', 'binge', ',', 'Fish', 'bringing', 'closing', ',', 'I', 'glad', 'place', 'O', 'trip', 'ended', ',', 'great', '!']\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print ([i for i in tokens if i not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And I hate to say this but I doubt I'll ever go back. \""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another example\n",
    "df.sentence[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and i hate to say this but i doubt i'll ever go back. \""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one of the normalizing steps is to convert everything to lowercase.\n",
    "lower_case = df.sentence[24].lower()\n",
    "lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and i hate to say this but i doubt i will ever go back.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the apostrophe for english language which will handle special cases.\n",
    "appos = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"i would\",\n",
    "\"i'd\" : \"i had\",\n",
    "\"i'll\" : \"i will\",\n",
    "\"i'm\" : \"i am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"i have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"\n",
    "}\n",
    "\n",
    "#split function of python. can be used for tokenization\n",
    "words = lower_case.split()\n",
    "reformed = [appos[word] if word in appos else word for word in words]\n",
    "reformed = \" \".join(reformed) \n",
    "reformed\n",
    "\n",
    "# i'll gets converted to i will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Went',\n",
       " 'on',\n",
       " 'a',\n",
       " '3',\n",
       " 'day',\n",
       " 'oyster',\n",
       " 'binge',\n",
       " ',',\n",
       " 'with',\n",
       " 'Fish',\n",
       " 'bringing',\n",
       " 'up',\n",
       " 'the',\n",
       " 'closing',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'so',\n",
       " 'glad',\n",
       " 'this',\n",
       " 'was',\n",
       " 'the',\n",
       " 'place',\n",
       " 'it',\n",
       " 'O',\n",
       " 'trip',\n",
       " 'ended',\n",
       " ',',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'great',\n",
       " '!']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the tokens for a particular sentence\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Went',\n",
       " 'on',\n",
       " 'a',\n",
       " 'day',\n",
       " 'oyster',\n",
       " 'binge',\n",
       " 'with',\n",
       " 'Fish',\n",
       " 'bringing',\n",
       " 'up',\n",
       " 'the',\n",
       " 'closing',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'so',\n",
       " 'glad',\n",
       " 'this',\n",
       " 'was',\n",
       " 'the',\n",
       " 'place',\n",
       " 'it',\n",
       " 'O',\n",
       " 'trip',\n",
       " 'ended',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'great']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the alphanumeric characters like numbers which do not hold significant importance\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Went on a 3 day oyster binge, with Fish bringing up the closing, and I am so glad this was the place it O trip ended, because it was so great!'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#an example sentence\n",
    "df.sentence[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    834\n",
      "0    317\n",
      "1     50\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After all that, they complained to me about th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avoid this place!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saul is the best restaurant on Smith Street an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The duck confit is always amazing and the foie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The wine list is interesting and has many good...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For the price, you cannot eat this well in Man...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I was very disappointed with this restaurant.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ive asked a cart attendant for a lotus leaf wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I had to ask her three times before she finall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Food was okay, nothing great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  sentiment\n",
       "0   Judging from previous posts this used to be a ...          0\n",
       "1   We, there were four of us, arrived at noon - t...          0\n",
       "2   They never brought us complimentary noodles, i...          0\n",
       "3   The food was lousy - too sweet or too salty an...          0\n",
       "4   After all that, they complained to me about th...          0\n",
       "5                                   Avoid this place!          0\n",
       "6   I have eaten at Saul, many times, the food is ...          2\n",
       "7   Saul is the best restaurant on Smith Street an...          2\n",
       "8   The duck confit is always amazing and the foie...          2\n",
       "9   The wine list is interesting and has many good...          2\n",
       "10  For the price, you cannot eat this well in Man...          2\n",
       "11      I was very disappointed with this restaurant.          0\n",
       "12  Ive asked a cart attendant for a lotus leaf wr...          0\n",
       "13  I had to ask her three times before she finall...          0\n",
       "14                      Food was okay, nothing great.          1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the sentiment to numeric values by using map function\n",
    "# 2 -> positive , 1-> neutral, 0-> negative\n",
    "df['sentiment'] = df.sentiment.map(lambda x: int(2) if x =='positive' else int(0) if x =='negative' else int(1) if x == 'neutral' else np.nan)\n",
    "print (df['sentiment'].value_counts())\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization which is the last step in data pre processing\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#plural words get converted into singular form\n",
    "#better gets converted into good. pos=\"a\" implies that we are referring to an adjective\n",
    "# running gets converted into run (Stemming)\n",
    "#pos=\"v\" implies that we are referring to a verb\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\")) #cacti is plural form of cactus\n",
    "print(lemmatizer.lemmatize(\"geese\")) \n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"running\",'v'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
